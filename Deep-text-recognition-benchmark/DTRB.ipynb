{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4RS6-5KKquw",
        "outputId": "e5300ff4-e666-4e09-81a8-8483062a7c11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-text-recognition-benchmark'...\n",
            "remote: Enumerating objects: 499, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 499 (delta 0), reused 1 (delta 0), pack-reused 495\u001b[K\n",
            "Receiving objects: 100% (499/499), 3.07 MiB | 23.30 MiB/s, done.\n",
            "Resolving deltas: 100% (301/301), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/clovaai/deep-text-recognition-benchmark.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd deep-text-recognition-benchmark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vG9Aqi-VL2Kf",
        "outputId": "06f05556-c9a0-4177-cff3-7633bce88046"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deep-text-recognition-benchmark\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run sample demo :"
      ],
      "metadata": {
        "id": "iB7xzOnpMVLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "download pretrained weights : https://drive.google.com/drive/folders/15WPsuPJDCzhp2SvYZLRj8mAlT3zmoAMW"
      ],
      "metadata": {
        "id": "b9U8mApjk_Wn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "download from google drive , using gdown\n"
      ],
      "metadata": {
        "id": "DQJ3pNZlo2gi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "import gdown\n",
        "\n",
        "!gdown 1b59rXuGGmKne1AuHnkgDzoYgKeETNMv9  # file ID"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytXJhcHaMOCi",
        "outputId": "f51035e8-d212-41d9-ba72-7a2772a295b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.7.22)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1b59rXuGGmKne1AuHnkgDzoYgKeETNMv9\n",
            "To: /content/deep-text-recognition-benchmark/TPS-ResNet-BiLSTM-Attn.pth\n",
            "100% 199M/199M [00:01<00:00, 194MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lmdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp2YG7G6qHUc",
        "outputId": "3cf9bf50-bbfa-45c2-ff70-e2283aeba4c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lmdb\n",
            "  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/299.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/299.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lmdb\n",
            "Successfully installed lmdb-1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 demo.py \\\n",
        "--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn \\\n",
        "--image_folder demo_image/ \\\n",
        "--saved_model TPS-ResNet-BiLSTM-Attn.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RVKQCKipS1G",
        "outputId": "5966471a-81fb-4feb-affd-94a837202916"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model input parameters 32 100 20 1 512 256 38 25 TPS ResNet BiLSTM Attn\n",
            "loading pretrained model from TPS-ResNet-BiLSTM-Attn.pth\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "--------------------------------------------------------------------------------\n",
            "image_path               \tpredicted_labels         \tconfidence score\n",
            "--------------------------------------------------------------------------------\n",
            "demo_image/demo_1.png    \tavailable                \t0.9999\n",
            "demo_image/demo_2.jpg    \tshakeshack               \t0.9530\n",
            "demo_image/demo_3.png    \tlondon                   \t0.9840\n",
            "demo_image/demo_4.png    \tgreenstead               \t0.9985\n",
            "demo_image/demo_5.png    \ttoast                    \t0.9961\n",
            "demo_image/demo_6.png    \tmerry                    \t0.9975\n",
            "demo_image/demo_7.png    \tunderground              \t1.0000\n",
            "demo_image/demo_8.jpg    \tronaldo                  \t0.8387\n",
            "demo_image/demo_9.jpg    \tbally                    \t0.7493\n",
            "demo_image/demo_10.jpg   \tuniversity               \t0.9998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "rooye 10 ta tasvire demo , dar file demo.py khorooji gereftan"
      ],
      "metadata": {
        "id": "lCxdIPDVqU_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lO2N1y9IqMMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train DTRB ON PERSIAN License Plate :"
      ],
      "metadata": {
        "id": "XjGipBVPrI_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "mikhaim az transfer learning estefade konim , va shabake RESNET dar bala ro ke ghablan train shode , rooye dataset khodemoon FINE TUNE konim"
      ],
      "metadata": {
        "id": "JLN4N5ArrcC-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "train our own non-latin dataset :"
      ],
      "metadata": {
        "id": "nY8Fo387r5BJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### WE NEED TO CREATE DATASET WITH lmdb FORMAT\n"
      ],
      "metadata": {
        "id": "zGppcIYjsJ8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "data <br/>\n",
        "├── gt.txt <br/>\n",
        "└── test <br/>\n",
        "    ├── word_1.png <br/>\n",
        "    ├── word_2.png <br/>\n",
        "    ├── word_3.png <br/>\n",
        "    └── ... <br/>\n",
        "\n",
        "<br/>\n",
        " image address  --------    its text <br/>\n",
        "test/word_1.png -----  Tiredness <br/>\n",
        "test/word_2.png -----  kills <br/>\n",
        "test/word_3.png -----  A <br/>\n",
        "... <br/>"
      ],
      "metadata": {
        "id": "3si579QksXHU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# here , **LABELS ARE TEXTS IN IMAGES**"
      ],
      "metadata": {
        "id": "5B7_mdJ5tqJt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "یک فایل دات تی اکس تی میسازیم <br/>\n",
        "آدرس هر عکس با متن توش رو قرار میدیم<br/>\n",
        "یعنی یک پوشه دیتا پر از عکس به علاوه یک فایل جی تی تکست که لیبل ها توشه\n",
        "این ساختار رو میدیم به فایل <br/> creat_lmbd_dataset.py\n",
        "<br/>\n",
        "بعد این میاد از روی عکس ها یک فایل ال ام دی بی میسازه\n",
        "<br/>\n",
        "اون فایل ال ام دی بی رو میدیم به train.py\n",
        "<br/>\n",
        "روش ترین بشه\n"
      ],
      "metadata": {
        "id": "jcwbOfP6t8Dn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "میایم توی فولدری که ساخته شده به نام دیپ تکست ریکاگنیشن یک فولدر ایجاد می کنیم به نام دیتا\n",
        "<br/>\n",
        "\n",
        "توی این فولدر یک فایل gt.txt  میسازیم\n",
        "<br/>\n",
        "\n",
        "و بعد یک فولدر که عکس ها رو بزاریم توش\n",
        "به نام ترین\n",
        "<br/>\n",
        "\n",
        "یک فولدر دیگه هم به نام ولیدیشین ایجاد میکنیم\n",
        "\n",
        "<br/>\n",
        "پس حالا چون دو تا فولدر داریم باید دو تا فایل جی تی هم داشته باشیم برای هرکدوم\n",
        "gt_train.txt\n",
        "gt_validation.txt\n",
        "\n",
        "### نکته : بین اسم فایل و متن مربوطه اش نباید اسپیس باشه بلکه باید یک تب بزنیم\n",
        "\n",
        "<br/>\n",
        "\n",
        "\n",
        "حالا میریم توی وی اس کد و اونجا فایل تکست رو میسازیم\n",
        "آدرس عکس + متن تصویر\n",
        "<br/>\n",
        "\n",
        "## Labeling :\n",
        "train/46469fhdhsj.jpg  13M89422\n",
        "train/834uy884848.jpg  74K48495 <br/>\n",
        ". <br/>\n",
        ". <br/>\n",
        ". <br/>\n",
        "<br/>\n",
        "in validation txt file :<br/>\n",
        "validtaion/h83y3rh7r.jpg  23Y94355\n",
        "\n",
        "\n",
        "\n",
        "حالا باید کتابخونه فایر رو نصب کنیم :"
      ],
      "metadata": {
        "id": "n81h19b6vT3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fire"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QX7Xismj195f",
        "outputId": "60e42f0d-eb70-4925-d3bc-761ccdd36bca"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fire\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/88.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m81.9/88.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire) (2.3.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116933 sha256=6ff25fc91391e3a6d281179d52e18c6587d5c6aca5d49e525c1a7d00c732853d\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "Successfully built fire\n",
            "Installing collected packages: fire\n",
            "Successfully installed fire-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "حالا گفته فایل create_lmdb_dataset.py <br/>\n",
        "رو اجرا بکن"
      ],
      "metadata": {
        "id": "A-JiF4Pn2EWH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "یک پوشه دیتاست ایجادد می کنیم و بعد داخلش یک فولدر ترین ایجاد می کنیم تا نتایج کد پایین رو اون تو ذخیره کنه\n",
        "<br/>\n",
        "deep-text-recognition-...  --->  dataset ---> train\n"
      ],
      "metadata": {
        "id": "4Iwfv7Jd2sXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 create_lmdb_dataset.py --inputPath data/ --gtFile data/gt_train.txt --outputPath dataset/train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpHDYZNv2Y0g",
        "outputId": "940bf973-4ea0-424b-cbce-ac6e1a32cf64"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created dataset with 72 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "اینجا یک دیتاست ساخته شد\n",
        "\n",
        "از روی عکس ها و لیبل ها اومد و فایل ام دی بی ساخت در آدرس زیر ⁉ <br/>\n",
        "\n",
        "dataset --> train  ----> data.mdb"
      ],
      "metadata": {
        "id": "st4TClYx2gbM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# az file haye .mdb dar TRAIN estefade mikone"
      ],
      "metadata": {
        "id": "6fq4J0xA2gXs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "حالا همین مسیر رو برای ولیدیشن انجام میدیم:\n",
        "<br/>\n",
        "و میگیم در این مسیر ذخیره کن نتایج و فایل های ام دی بی رو\n",
        "<br/>\n",
        "deep-text-recognition... / dataset / validation"
      ],
      "metadata": {
        "id": "AxVYETei4sDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 create_lmdb_dataset.py --inputPath data/ --gtFile data/gt_validation.txt --outputPath dataset/validation"
      ],
      "metadata": {
        "id": "IExIczyo4qai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5bZKdeJZ5mOO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAIN :"
      ],
      "metadata": {
        "id": "THZYgp_q5xrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train.py \\\n",
        "--train_data dataset/train --valid_data dataset/validation \\\n",
        "--select_data / --batch_ratio 1 --batch_max_length 8 --valInterval 100 \\\n",
        "--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXaHxGgmrBEN",
        "outputId": "4a141a29-5912-416a-de0c-f4a890602cff"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering the images containing characters which are not in opt.character\n",
            "Filtering the images whose label is longer than opt.batch_max_length\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root: dataset/train\n",
            "opt.select_data: ['/']\n",
            "opt.batch_ratio: ['1']\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root:    dataset/train\t dataset: /\n",
            "sub-directory:\t/.\t num samples: 70\n",
            "num total samples of /: 70 x 1.0 (total_data_usage_ratio) = 70\n",
            "num samples of / per batch: 192 x 1.0 (batch_ratio) = 192\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "--------------------------------------------------------------------------------\n",
            "Total_batch_size: 192 = 192\n",
            "--------------------------------------------------------------------------------\n",
            "dataset_root:    dataset/validation\t dataset: /\n",
            "sub-directory:\t/.\t num samples: 10\n",
            "--------------------------------------------------------------------------------\n",
            "model input parameters 32 100 20 1 512 256 38 8 TPS ResNet BiLSTM Attn\n",
            "Skip Transformation.LocalizationNetwork.localization_fc2.weight as it is already initialized\n",
            "Skip Transformation.LocalizationNetwork.localization_fc2.bias as it is already initialized\n",
            "Model:\n",
            "DataParallel(\n",
            "  (module): Model(\n",
            "    (Transformation): TPS_SpatialTransformerNetwork(\n",
            "      (LocalizationNetwork): LocalizationNetwork(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (6): ReLU(inplace=True)\n",
            "          (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (10): ReLU(inplace=True)\n",
            "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "          (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (14): ReLU(inplace=True)\n",
            "          (15): AdaptiveAvgPool2d(output_size=1)\n",
            "        )\n",
            "        (localization_fc1): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "        )\n",
            "        (localization_fc2): Linear(in_features=256, out_features=40, bias=True)\n",
            "      )\n",
            "      (GridGenerator): GridGenerator()\n",
            "    )\n",
            "    (FeatureExtraction): ResNet_FeatureExtractor(\n",
            "      (ConvNet): ResNet(\n",
            "        (conv0_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn0_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv0_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn0_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (layer1): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (layer2): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (maxpool3): MaxPool2d(kernel_size=2, stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
            "        (layer3): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (3): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (4): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (layer4): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "          (2): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv4_1): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), bias=False)\n",
            "        (bn4_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv4_2): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
            "        (bn4_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
            "    (SequenceModeling): Sequential(\n",
            "      (0): BidirectionalLSTM(\n",
            "        (rnn): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
            "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
            "      )\n",
            "      (1): BidirectionalLSTM(\n",
            "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
            "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (Prediction): Attention(\n",
            "      (attention_cell): AttentionCell(\n",
            "        (i2h): Linear(in_features=256, out_features=256, bias=False)\n",
            "        (h2h): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (score): Linear(in_features=256, out_features=1, bias=False)\n",
            "        (rnn): LSTMCell(294, 256)\n",
            "      )\n",
            "      (generator): Linear(in_features=256, out_features=38, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Trainable params num :  49555182\n",
            "Optimizer:\n",
            "Adadelta (\n",
            "Parameter Group 0\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    lr: 1\n",
            "    maximize: False\n",
            "    rho: 0.95\n",
            "    weight_decay: 0\n",
            ")\n",
            "------------ Options -------------\n",
            "exp_name: TPS-ResNet-BiLSTM-Attn-Seed1111\n",
            "train_data: dataset/train\n",
            "valid_data: dataset/validation\n",
            "manualSeed: 1111\n",
            "workers: 4\n",
            "batch_size: 192\n",
            "num_iter: 300000\n",
            "valInterval: 100\n",
            "saved_model: \n",
            "FT: False\n",
            "adam: False\n",
            "lr: 1\n",
            "beta1: 0.9\n",
            "rho: 0.95\n",
            "eps: 1e-08\n",
            "grad_clip: 5\n",
            "baiduCTC: False\n",
            "select_data: ['/']\n",
            "batch_ratio: ['1']\n",
            "total_data_usage_ratio: 1.0\n",
            "batch_max_length: 8\n",
            "imgH: 32\n",
            "imgW: 100\n",
            "rgb: False\n",
            "character: 0123456789abcdefghijklmnopqrstuvwxyz\n",
            "sensitive: False\n",
            "PAD: False\n",
            "data_filtering_off: False\n",
            "Transformation: TPS\n",
            "FeatureExtraction: ResNet\n",
            "SequenceModeling: BiLSTM\n",
            "Prediction: Attn\n",
            "num_fiducial: 20\n",
            "input_channel: 1\n",
            "output_channel: 512\n",
            "hidden_size: 256\n",
            "num_gpu: 1\n",
            "num_class: 38\n",
            "---------------------------------------\n",
            "\n",
            "[1/300000] Train loss: 3.66497, Valid loss: 3.65104, Elapsed_time: 7.24423\n",
            "Current_accuracy : 0.000, Current_norm_ED  : 0.01\n",
            "Best_accuracy    : 0.000, Best_norm_ED     : 0.01\n",
            "--------------------------------------------------------------------------------\n",
            "Ground Truth              | Prediction                | Confidence Score & T/F\n",
            "--------------------------------------------------------------------------------\n",
            "46w47799                  | kkkkkkkk                  | 0.0000\tFalse\n",
            "91w53340                  | 22222222                  | 0.0000\tFalse\n",
            "34b29850                  | kkkkkkkk                  | 0.0000\tFalse\n",
            "22c39688                  | kkkkkkkk                  | 0.0000\tFalse\n",
            "58r45540                  | k22qqqqq                  | 0.0000\tFalse\n",
            "--------------------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/deep-text-recognition-benchmark/dataset.py\", line 87, in get_batch\n",
            "    image, text = next(data_loader_iter)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1318, in _next_data\n",
            "    raise StopIteration\n",
            "StopIteration\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/deep-text-recognition-benchmark/train.py\", line 317, in <module>\n",
            "    train(opt)\n",
            "  File \"/content/deep-text-recognition-benchmark/train.py\", line 147, in train\n",
            "    image_tensors, labels = train_dataset.get_batch()\n",
            "  File \"/content/deep-text-recognition-benchmark/dataset.py\", line 92, in get_batch\n",
            "    image, text = next(self.dataloader_iter_list[i])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1328, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1284, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1132, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.10/queue.py\", line 180, in get\n",
            "    self.not_empty.wait(remaining)\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 324, in wait\n",
            "    gotit = waiter.acquire(True, timeout)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "در فایل train.py ⁉\n",
        "batch_max_length = default=8\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TLtzuoPJ7KGU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "num_iter = (300000 / batch size=192 ) / number of batches"
      ],
      "metadata": {
        "id": "2xUCzRV78Dka"
      }
    }
  ]
}